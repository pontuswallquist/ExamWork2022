

model_14 without penalty
Trained for 100 games
Learning rate: 0.002
Epsilon decay: 0.9975
Gamma: 0.85
75 % winrate vs Random agent

Model 4 without penalty for losing servants
Trained for 500 games = 18h 40 min
Epsilon decay = 0.9975
gamma = 0.85
learning rate = 0.002
62 % winrate against model_14, Avg score: 38.5


Model 7 with penalty for losing servants
Trained for 250 games = 7h 50 min
epsilon decay = 0.998
gamma = 0.95
learning rate = 0.001
59 % winrate vs Model 14, Avg score: 35
57 % winrate vs Model 4,  Avg score: 35


Model 8 with penalty for losing servants
Trained for 1000 games = 40h 30 min
epsilon decay = 0.9975
gamma = 0.85
learning rate = 0.001
57 % winrate vs model 4, Avg score: 37.25
76.5 % winrate vs model 14, Avg score: 40.7
58 % winrate vs model 7, Avg score: 36.3

Model 10 with penalty and target train every other game
Trained for 500 games
epsilon_decay = 0.999
gamma = 0.95
learning_rate = 0.0001
38 % winrate vs model 8 as Blue, 65 % winrate as Red
66 % winrate vs model 14
75 % winrate vs model 4

Model 10 and model 8 are best at this point

Model 11 with penalty and target train every game
Trained for 500 games
LR = 0.0001
gamma = 0.85
32 % winrate vs model 10
61 % winrate vs model 8


Model 15, Linear Activation Func and target train every 5 games
91 % winrate vs model 16
72 % winrate vs Random

Model 16, Linear Activation Func and target train every 10 games
35 % winrate vs Random
6 % winrate vs model 15

Model 18, Linear Activation Func and target train every game
0 % winrate vs Random
0 % winrate vs model 15
 % winrate vs model 16

Model 19, Linear Activation Func and target train every game


